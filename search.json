[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Quarto Blog",
    "section": "",
    "text": "Discrete Distributions\n\n\n\n\n\n\nStatistics\n\n\n\n\n\n\n\n\n\nJan 2, 2027\n\n\nShreya Anbu\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to SciPy\n\n\n\n\n\nIntroduction Post\n\n\n\n\n\nFeb 25, 2025\n\n\nShreya Anbu\n\n\n\n\n\n\n\n\n\n\n\n\nSimple Visualisation\n\n\n\n\n\n\nStatistics\n\n\n\n\n\n\n\n\n\nFeb 14, 2025\n\n\nNipun Batra\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome.html",
    "href": "posts/welcome.html",
    "title": "Introduction to SciPy",
    "section": "",
    "text": "Introduction to SciPy\n\n\nscipy.stats Module\nIt is a very helpful module used for statistical analysis and modeling.\n\nThis module contains a large number of probability distributions, summary and frequency statistics, correlation functions and statistical tests, masked statistics, kernel density estimation, quasi-Monte Carlo functionality, and more.\n\nYou can find more information on the official documentation page.\n\n\nInstallation\nIf you already have Python installed, you can install SciPy with pip by executing the following in a terminal/shell:\npython -m pip install scipy\nWhile using Jupyter Notebook or Google Colab, just use the following line before writing the main code:\nimport scipy\n\n\nComparison with PyTorch Distributions\nCan’t both of these modules used for modeling distributions? Why do they exist as two separate models then?  PyTorch module provides more functionality for deep learning applications, whereas SciPy is more suitable for statistical modeling, having a more user-friendly interface for statisticians.\n\n\n\n\n\n\n\n\nFeature\nPyTorch Version\nScipPy Version\n\n\n\n\nCreating a Distribution\ntorch.distributions.Poisson(rate_param)\nscipy.stats.poisson(rate_param)\n\n\nCreating a Sample\ndist.sample((n, ))\ndist.rvs(size = n)\n\n\nCalculating PMF\ndist.log_prob(x).exp()\ndist.pmf(x)\n\n\n\nWe can see with the last comparison how SciPy has more direct, easy to read functions for obtaining basic values out of a distribution.\n\n\nDifferent Kinds of Distributions Available\nThere are a lot of things contained by the scipy.stats module, but we will be looking into the different kinds of distributions available for us to use. There are three kinds: continuous, discrete and multivariate. \n\nContinuous Distribution: Random variable can take on any value within a specified range, meaning there are infinitely many possible values between any two points;\nDiscrete Distribution: Random variable can only take on a finite number of distinct values, usually whole numbers;\nMultivariate Distribution: Describes the probability of multiple random variables occurring simultaneously, considering their potential relationships and correlations with each other.\n\nThere are tons of distributions available under each kind that we can use, which can be explored again in the official documentation.\n\n\n\nScreenshot from official documentation\n\n\nThe above image shows the start of the list of functionalities, which barely scratches the surface."
  },
  {
    "objectID": "posts/Static_Version_of_Discrete_Distributions_in_SciPy (1).html",
    "href": "posts/Static_Version_of_Discrete_Distributions_in_SciPy (1).html",
    "title": "Discrete Distributions",
    "section": "",
    "text": "Bernoulli distribution\nBernoulli Distribution is a type of discrete probability distribution where every experiment conducted asks a question that can be answered only in yes or no. In other words, the random variable can be 1 with a probability p or it can be 0 with a probability (1 - p). Such an experiment is called a Bernoulli trial. A pass or fail exam can be modeled by a Bernoulli Distribution.\nSuppose there is an experiment where you flip a coin that is fair. If the outcome of the flip is heads then you will win. This means that the probability of getting heads is p = 1/2. If X is the random variable following a Bernoulli Distribution, we get P(X = 1) = p = 1/2.\nA binomial random variable, X, is also known as an indicator variable. This is because if an event results in success then X = 1 and if the outcome is a failure then X = 0. X can be written as X ∼Bernoulli (p), where p is the parameter. The formulas for Bernoulli distribution are given by the probability mass function (pmf) and the cumulative distribution function (CDF).\n\n\n\nimage.png\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import bernoulli\nimport ipywidgets as widgets\nfrom ipywidgets import interact\n\np = 0.3\nplt.figure(figsize=(5, 4))\nx = np.array([0, 1])\npmf_vals = bernoulli.pmf(x, p)\nplt.plot(x, pmf_vals, 'bo', ms=8, label='Bernoulli PMF')\nplt.vlines(x, 0, pmf_vals, colors='b', lw=5, alpha=0.5)\nplt.xticks([0, 1])\nplt.xlabel(\"X\")\nplt.ylabel(\"PMF\")\nplt.title(f\"Bernoulli PMF (p={p:.2f})\")\nplt.legend()\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBinomial Distribution\nA discrete probability distribution that includes the number of trials n, probability of success and probability of failure is called as Binomial distribution.\nThe probability mass function of the Binomial distribution is given by:\n\n\n\nimage.png\n\n\nThe probability mass function above is defined in the “standardized” form. To shift distribution use the loc parameter. Specifically, binom.pmf(k, n, p, loc) is identically equivalent to binom.pmf(k - loc, n, p).\nBinomial Distribution is used where we have only two possible outcomes. Let’s see some of the areas where Binomial Distribution can be used:\n\nTo find the number of male and female students in an institute.\nTo find the likeability of something in Yes or No.\nTo find defective or good products manufactured in a factory.\nTo find positive and negative reviews on a product.\nVotes are collected in the form of 0 or 1.\n\n\nimport scipy.stats as stats\nfrom scipy.stats import binom\n\n\nn = 10\np = 0.4\nx = np.arange(0, n + 1)\nplt.figure(figsize=(7, 5))\nplt.plot(x, stats.binom.pmf(x, n, p), 'bo', ms=8, label='binom pmf')\nplt.vlines(x, 0, stats.binom.pmf(x, n, p), colors='b', lw=5, alpha=0.5)\nplt.title(f'Binomial Distribution PMF (n={n}, p={p:.2f})')\nplt.xlabel('Number of Successes')\nplt.ylabel('Probability Mass')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nPoisson Distribution\nA Poisson distribution is commonly seen in real life situations where events occur independently over a fixed time interval, such as: the number of phone calls received at a call center per hour, the number of customers arriving at a store in a given time frame, the number of defects in a manufactured product batch, or the number of car accidents at a particular intersection per day.\nWhenever there is an average rate of an event happening, it can most probably be modelled by a poisson distribution. It will help us predict the probability of the same event happening at different frequencies.\n\nfrom scipy.stats import poisson\n\nmu = 1.2\nx = np.arange(poisson.ppf(0.01, mu), poisson.ppf(0.99, mu))\nplt.plot(x, poisson.pmf(x, mu), 'bo', ms=8, label='Poisson PMF')\nplt.vlines(x, 0, poisson.pmf(x, mu), colors='b', lw=5, alpha=0.5)\nplt.title(f'Poisson Distribution (mu={mu})')\nplt.xlabel('x')\nplt.ylabel('PMF')\nplt.show()"
  },
  {
    "objectID": "posts/visualisation.html",
    "href": "posts/visualisation.html",
    "title": "Simple Visualisation",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nplt.plot(x, y)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ES 114 Assignment",
    "section": "",
    "text": "This blog website has been created as part of the course of our BTech first year in IIT Gandhinagar, titled ‘Probability, Statistics and Data Visualizations’.\nStudent’s Details: Prachi Jindal (24110264) Shah Khushi (24110326) Shreya Anbu (24110331)"
  }
]