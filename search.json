[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Quarto Blog",
    "section": "",
    "text": "Introduction to SciPy\n\n\n\n\n\nIntroduction Post\n\n\n\n\n\nFeb 25, 2025\n\n\nShreya Anbu\n\n\n\n\n\n\n\n\n\n\n\n\nSimple Visualisation\n\n\n\n\n\n\nML\n\n\n\n\n\n\n\n\n\nFeb 14, 2025\n\n\nNipun Batra\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome.html",
    "href": "posts/welcome.html",
    "title": "Introduction to SciPy",
    "section": "",
    "text": "Introduction to SciPy\n\n\nscipy.stats Module\nIt is a very helpful module used for statistical analysis and modeling.\n\nThis module contains a large number of probability distributions, summary and frequency statistics, correlation functions and statistical tests, masked statistics, kernel density estimation, quasi-Monte Carlo functionality, and more.\n\nYou can find more information on the official documentation page.\n\n\nInstallation\nIf you already have Python installed, you can install SciPy with pip by executing the following in a terminal/shell:\npython -m pip install scipy\nWhile using Jupyter Notebook or Google Colab, just use the following line before writing the main code:\nimport scipy\n\n\nComparison with PyTorch Distributions\nCan‚Äôt both of these modules used for modeling distributions? Why do they exist as two separate models then?  PyTorch module provides more functionality for deep learning applications, whereas SciPy is more suitable for statistical modeling, having a more user-friendly interface for statisticians.\n\n\n\n\n\n\n\n\nFeature\nPyTorch Version\nScipPy Version\n\n\n\n\nCreating a Distribution\ntorch.distributions.Poisson(rate_param)\nscipy.stats.poisson(rate_param)\n\n\nCreating a Sample\ndist.sample((n, ))\ndist.rvs(size = n)\n\n\nCalculating PMF\ndist.log_prob(x).exp()\ndist.pmf(x)\n\n\n\nWe can see with the last comparison how SciPy has more direct, easy to read functions for obtaining basic values out of a distribution.\n\n\nDifferent Kinds of Distributions Available\nThere are a lot of things contained by the scipy.stats module, but we will be looking into the different kinds of distributions available for us to use. There are three kinds: continuous, discrete and multivariate. \n\nContinuous Distribution: Random variable can take on any value within a specified range, meaning there are infinitely many possible values between any two points;\nDiscrete Distribution: Random variable can only take on a finite number of distinct values, usually whole numbers;\nMultivariate Distribution: Describes the probability of multiple random variables occurring simultaneously, considering their potential relationships and correlations with each other.\n\nThere are tons of distributions available under each kind that we can use, which can be explored again in the official documentation.\n\n\n\nScreenshot from official documentation\n\n\nThe above image shows the start of the list of functionalities, which barely scratches the surface."
  },
  {
    "objectID": "posts/Normal distribution.html",
    "href": "posts/Normal distribution.html",
    "title": "Quarto Template",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\n\nthe data is taken from the website - https://www.kaggle.com/datasets/mustafaali96/weight-height?resource=download\n\ndf=pd.read_csv(\"weight-height.csv\")\nprint(df.head())\n\n  Gender     Height      Weight\n0   Male  73.847017  241.893563\n1   Male  68.781904  162.310473\n2   Male  74.110105  212.740856\n3   Male  71.730978  220.042470\n4   Male  69.881796  206.349801\n\n\n\nmean=df[\"Height\"].mean()\nprint((mean))\n\n66.36755975482124\n\n\n\nstandard_deviation=df[\"Height\"].std()\nprint((standard_deviation))\n\n3.8475281207732324\n\n\n\nplt.hist(df[\"Height\"], bins =60)\nplt.xlabel(\"Standardized Return\")\nplt.ylabel(\"Density\")\nplt.title(\"Histogram of Standardized Stock Returns\")\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n\nloc, scale = stats.norm.fit(df[\"Height\"])\nloc, scale\n\n(66.36755975482124, 3.84733573955754)\n\n\n\nx_vals = np.linspace(min(df[\"Height\"]), max(df[\"Height\"]), 1000)\n\n\npdf=stats.norm.pdf(x_vals, loc=loc, scale=scale)\nplt.plot(x_vals, pdf, color=\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\n# Fit a normal distribution\nmu, sigma = stats.norm.fit(df[\"Height\"])  # Should be close to (0,1) for standardized data\n\n# Generate PDF values\nx_vals = np.linspace(min(df[\"Height\"]), max(df[\"Height\"]), 1000)\npdf_vals = stats.norm.pdf(x_vals, mu, sigma)\n\n# Plot the fitted normal distribution\nplt.figure(figsize=(8, 5))\nplt.plot(x_vals, pdf_vals, label=f\"Normal Fit (Œº={mu:.2f}, œÉ={sigma:.2f})\", color='red')\nplt.hist(df[\"Height\"], bins=20, density=True, alpha=0.5, label=\"Histogram\")\nplt.xlabel(\"Standardized Return\")\nplt.ylabel(\"Density\")\nplt.title(\"Fitted Normal Distribution PDF\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nPMF V/S PDF 1. PMF is for Discrete Data The PMF (Probability Mass Function) applies to discrete random variables, meaning variables that take on countable values (e.g., number of students, number of cars). It gives the probability of exact values occurring.\n\nPDF is for Continuous Data Our dataset consists of continuous stock returns (e.g., real numbers like 0.52, -1.23, 1.89). For continuous distributions, the probability of a single exact value occurring is zero because there are infinitely many possible values. Instead of a PMF, we use a Probability Density Function (PDF) to describe the relative likelihood of values falling within an interval.\n\nSince stock returns are continuous, we cannot use a PMF. Instead, we must use a PDF (such as a normal distribution or kernel density estimation) to describe their distribution.\nThe Cumulative Distribution Function (CDF) gives the probability that a random variable ùëã is less than or equal to a specific value ùë•, i.e., F(x)=P(X‚â§x) It helps in understanding the cumulative probability of the data.\n\ncdf=stats.norm.cdf(x_vals, loc=loc, scale=scale)\nplt.plot(x_vals, cdf, color=\"black\")\nplt.show()\n\n\n\n\n\n\n\n\nPPF The Percent-Point Function (PPF) is the inverse of the Cumulative Distribution Function (CDF). It is also called the quantile function because it helps find the value of a random variable at a given probability.\nIn simple terms, if:\nùêπ(ùë•)=ùëÉ(ùëã‚â§ùë•)\nthen PPF finds ùë• for a given probability ùëù, i.e., ùë•=ùêπ‚àí1(ùëù)\nThis helps in determining critical values for a normal distribution.\n\np_vals = np.linspace(0.01, 0.99, 1000)\nppf=stats.norm.ppf(p_vals, loc=loc, scale=scale)\nplt.plot(p_vals, ppf, color=\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\ncdf_1=stats.norm.cdf(1, loc=loc, scale=scale)\ncdf_1\n\n4.840940191061131e-65\n\n\n\nmu, sigma = stats.norm.fit(df[\"Height\"])\n\n# Generate height values for CDF\nx_vals = np.linspace(min(df[\"Height\"]), max(df[\"Height\"]), 1000)\n\n# Compute the CDF\ncdf_vals = stats.norm.cdf(x_vals, loc=mu, scale=sigma)\n\n# Choose a specific height (e.g., 70 inches) to mark on the plot\nx_mark = 70\ncdf_mark = stats.norm.cdf(x_mark, loc=mu, scale=sigma)\n\n# Plot the CDF\nplt.figure(figsize=(8, 5))\nplt.plot(x_vals, cdf_vals, color=\"black\", label=\"Normal CDF\")\n\n# Mark the chosen height on the CDF\nplt.vlines(x_mark, 0, cdf_mark, linestyle=\":\", color=\"red\", label=f\"CDF at {x_mark}\")\nplt.hlines(cdf_mark, min(x_vals), x_mark, linestyle=\":\", color=\"red\")\n\n# Labels and title\nplt.xlabel(\"Height\")\nplt.ylabel(\"Cumulative Probability\")\nplt.title(\"Cumulative Distribution Function (CDF) of Heights\")\nplt.legend()\nplt.grid()\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\nA normal distribution, also called the bell curve, has many real world examples. Some examples include test scores, height, shoe size, IQ, and income."
  },
  {
    "objectID": "posts/visualisation.html",
    "href": "posts/visualisation.html",
    "title": "Simple Visualisation",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\n\nplt.plot(x, y)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quarto Template",
    "section": "",
    "text": "Quarto template Text!"
  }
]